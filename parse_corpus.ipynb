{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "srts = ['ㄱ', 'ㄲ', 'ㄴ', 'ㄷ', 'ㄸ', 'ㄹ', 'ㅁ', 'ㅂ', 'ㅃ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅉ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "mids = ['ㅏ', 'ㅐ', 'ㅑ', 'ㅒ', 'ㅓ', 'ㅔ', 'ㅕ', 'ㅖ', 'ㅗ', 'ㅘ', 'ㅙ', 'ㅚ', 'ㅛ', 'ㅜ', 'ㅝ', 'ㅞ', 'ㅟ', 'ㅠ', 'ㅡ', 'ㅢ', 'ㅣ']\n",
    "ends = ['', 'ㄱ', 'ㄲ', 'ㄳ', 'ㄴ', 'ㄵ', 'ㄶ', 'ㄷ', 'ㄹ', 'ㄺ', 'ㄻ', 'ㄼ', 'ㄽ', 'ㄾ', 'ㄿ', 'ㅀ', 'ㅁ', 'ㅂ', 'ㅄ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "\n",
    "\n",
    "def is_hangul(char):\n",
    "    if ord('가') <= ord(char) <= ord('힣'):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def split_char(char):\n",
    "    key = ord(char[0]) - 44032\n",
    "    end = int(key % 28)\n",
    "    mid = int((key - end) / 28 % 21)\n",
    "    srt = int((key / 28 - mid) / 21)\n",
    "    return srts[srt], mids[mid], ends[end]\n",
    "\n",
    "\n",
    "def merge_char(srt, mid, end):\n",
    "    i = 44032 + 28 * 21 * srts.index(srt) + 28 * mids.index(mid) + ends.index(end)\n",
    "    return chr(i)\n",
    "\n",
    "\n",
    "def split_text(text):\n",
    "    output = list()\n",
    "    for w in text:\n",
    "        if ord('가') <= ord(w) <= ord('힣'):\n",
    "            output.append(''.join(split_char(w)))\n",
    "        else:\n",
    "            output.append(w)\n",
    "    return ''.join(output)\n",
    "\n",
    "\n",
    "def merge_text(text):\n",
    "    output = list()\n",
    "    text = deque([w for w in text])\n",
    "    while len(text) != 0:\n",
    "        if len(text) >= 3 and text[0] in srts and text[1] in mids and text[2] in ends and (len(text) == 3 or text[3] not in mids):\n",
    "            output.append(merge_char(text.popleft(), text.popleft(), text.popleft()))\n",
    "        elif len(text) >=2 and text[0] in srts and text[1] in mids:\n",
    "            output.append(merge_char(text.popleft(), text.popleft(), ''))\n",
    "        else:\n",
    "            output.append(text.popleft())\n",
    "\n",
    "    return ''.join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_tagged(tagged):\n",
    "    tags = tagged.split('+')\n",
    "    tags = [tag.split('/') for tag in tags]\n",
    "    umjol_tags = list()\n",
    "\n",
    "    for tag in tags:\n",
    "        for letter in tag[0]:\n",
    "            umjol_tags.append((letter, tag[1]))\n",
    "\n",
    "    return umjol_tags\n",
    "\n",
    "\n",
    "def process_ejol(ejol):\n",
    "    code, origin, tagged = ejol.split('\\t')\n",
    "    origin = [l for l in origin]\n",
    "    tagged = parse_tagged(tagged)\n",
    "\n",
    "    if len(origin) > len(tagged):\n",
    "        if False in list(map(lambda x: is_hangul(x), origin)):\n",
    "            raise Exception('Not Enough Tagged')\n",
    "\n",
    "    result = list()\n",
    "    i = 0\n",
    "    for j, tag in enumerate(tagged):\n",
    "        if j == 0:\n",
    "            result.append(0)\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        if i >= len(origin):\n",
    "            result.append(-1)\n",
    "            continue\n",
    "\n",
    "        if origin[i] == tag[0]:\n",
    "            result.append(i)\n",
    "            i += 1\n",
    "        elif tag[0] in origin[i:]:\n",
    "            i = origin.index(tag[0], i)\n",
    "            if result[-1] != -1 and i - result[-1] > 2:\n",
    "                result.append(-1)\n",
    "            else:\n",
    "                result.append(i)\n",
    "                i += 1\n",
    "        else:\n",
    "            result.append(-1)\n",
    "\n",
    "    for i, r in enumerate(result):\n",
    "        if r == -1:\n",
    "            if result[i - 1] + 1 in result:\n",
    "                result[i] = result[i - 1]\n",
    "            else:\n",
    "                result[i] = result[i - 1] + 1\n",
    "\n",
    "        if result[i] > len(origin) - 1:\n",
    "            result[i] = len(origin) - 1\n",
    "\n",
    "        if i >= 2 and result[i - 2] == result[i]:\n",
    "            if is_hangul(origin[i - 2]) and is_hangul(tagged[i - 2][0]) and \\\n",
    "                            split_char(origin[i - 2])[0:2] == split_char(tagged[i - 2][0])[0:2]:\n",
    "                pass\n",
    "            else:\n",
    "                result[i - 2] -= 1\n",
    "\n",
    "    return origin, tagged, result\n",
    "\n",
    "\n",
    "def parse_sentence(stc):\n",
    "    stc = stc.text.replace(' ', '').strip()\n",
    "    ejols = stc.split('\\n')\n",
    "    sentence = list()\n",
    "    sentence.append({'letter': '<시작>', 'pos': [{'letter': '<시작>', 'tag': 'ZST'}]})\n",
    "\n",
    "    for ejol in ejols:\n",
    "        letters = list()\n",
    "        origin, tagged, result = process_ejol(ejol)\n",
    "        for l in origin:\n",
    "            letters.append({'letter': l, 'pos': []})\n",
    "        for i, t in enumerate(tagged):\n",
    "            letters[result[i]]['pos'].append({'letter': t[0], 'tag': t[1]})\n",
    "        for l in letters:\n",
    "            if len(l['pos']) == 0:\n",
    "                l['pos'].append({'letter': l['letter'], 'tag': 'ZNO'})\n",
    "        sentence.extend(letters)\n",
    "        sentence.append({'letter': ' ', 'pos': [{'letter': ' ', 'tag': 'ZSP'}]})\n",
    "    \n",
    "    sentence.pop(-1)\n",
    "    sentence.append({'letter': '<끝>', 'pos': [{'letter': '<끝>', 'tag': 'ZED'}]})\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [08:20<00:00, 10.42it/s]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "import simplejson as json\n",
    "from tqdm import tqdm\n",
    "\n",
    "korpus_dir = Path('corpus')\n",
    "file_list = [file for file in korpus_dir.iterdir() if file.name.endswith('.txt') and not file.name.startswith('.')]\n",
    "\n",
    "output = open('output.txt', 'w', encoding='utf-8')\n",
    "for file in tqdm(file_list):\n",
    "    c_file = file.open('r', encoding='utf-16 le')\n",
    "    parsed = BeautifulSoup(c_file.read(), 'html.parser')\n",
    "    ps = parsed.find_all('p')\n",
    "\n",
    "    for p in ps:\n",
    "        try:\n",
    "            output.write(json.dumps(parse_sentence(p), ensure_ascii=False) + '\\n')\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "output.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
